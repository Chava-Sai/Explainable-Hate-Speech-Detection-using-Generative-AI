{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI0aK11pZIFb"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "data_path = 'TWITTER+youtube.csv'\n",
        "df = pd.read_csv(data_path, encoding='latin1')\n",
        "\n",
        "# Prepare a FastText compatible input file for both \"Fake\" and \"Hate\" detection\n",
        "fasttext_input_file = 'fasttext_input.txt'\n",
        "with open(fasttext_input_file, 'w', encoding='utf-8') as f:\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['Tweet'].replace('\\n', '')  # Remove newline characters\n",
        "        fake_label = '_labelfake' if row['Fake'] == 1 else '__label_not_fake'\n",
        "        hate_label = '_labelhate' if row['Hate'] == 1 else '__label_not_hate'\n",
        "        line = f\"{fake_label} {hate_label} {text}\\n\"\n",
        "        f.write(line)\n",
        "\n",
        "# Initialize a list to capture the training loss\n",
        "loss_values = []\n",
        "\n",
        "# Train a FastText model for both \"Fake\" and \"Hate\" detection\n",
        "model = fasttext.train_supervised(\n",
        "    input=fasttext_input_file,\n",
        "    loss='ova',  # 'ova' stands for one-vs-all (multilabel classification)\n",
        "    verbose=1,\n",
        "    thread=4  # You can adjust the number of threads for training\n",
        ")\n",
        "\n",
        "# Save the trained model to a file\n",
        "model_output_path = 'fasttext_model.bin'\n",
        "model.save_model(model_output_path)\n",
        "\n",
        "# Test the model for \"Fake\" and \"Hate\" detection\n",
        "X_test = df['Tweet']\n",
        "y_test_fake = df['Fake']\n",
        "y_test_hate = df['Hate']\n",
        "\n",
        "def predict(text):\n",
        "    labels, _ = model.predict(text.replace('\\n', ''), k=2)\n",
        "    return int('_labelfake' in labels) , int('__label_hate' in labels)\n",
        "\n",
        "y_pred_fake, y_pred_hate = zip(*X_test.apply(predict))\n",
        "\n",
        "# Compute confusion matrices\n",
        "cm_fake = confusion_matrix(y_test_fake, y_pred_fake)\n",
        "cm_hate = confusion_matrix(y_test_hate, y_pred_hate)\n",
        "\n",
        "# Compute classification reports\n",
        "report_fake = classification_report(y_test_fake, y_pred_fake, target_names=[\"Not Fake\", \"Fake\"])\n",
        "report_hate = classification_report(y_test_hate, y_pred_hate, target_names=[\"Not Hate\", \"Hate\"])\n",
        "\n",
        "print(\"Confusion Matrix for 'Fake' detection:\")\n",
        "print(cm_fake)\n",
        "\n",
        "print(\"\\nClassification Report for 'Fake' detection:\")\n",
        "print(report_fake)\n",
        "\n",
        "print(\"\\nConfusion Matrix for 'Hate' detection:\")\n",
        "print(cm_hate)\n",
        "\n",
        "print(\"\\nClassification Report for 'Hate' detection:\")\n",
        "print(report_hate)\n",
        "\n",
        "# Manual calculation of training loss values\n",
        "for epoch in range(1, 11):  # Adjust the number of epochs as needed\n",
        "    loss = model.test(fasttext_input_file)\n",
        "    loss_values.append(loss[1])  # The second element contains the loss\n",
        "\n",
        "# Plot the loss curve using Matplotlib\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, 11), loss_values, marker='o', linestyle='-')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ3e_rDmZNdg",
        "outputId": "328c1310-bdf7-444d-ea85-7aaa488dbabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m608.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.23.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4199774 sha256=902b9907be8858a487af55be34287452699569306e9fdfaefd8f4c4256820e36\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeS7Gas1ZRN4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}